---
title: "Semantic Cache"
description: "Smart caching that understands meaning, not just exact matches"
icon: "brain"
---

Semantic cache uses AI to understand the meaning of requests, automatically caching responses for similar queries even when they're worded differently. This intelligent caching is enabled by default and can dramatically reduce costs and response times.

<Note>
**Enabled by Default**: Semantic caching works automatically - no configuration needed for most applications.
</Note>

## How Semantic Caching Works

<Steps>
  <Step title="Request Analysis">
    Incoming prompts are converted to embeddings that capture their semantic meaning
  </Step>
  <Step title="Similarity Search">
    The system searches for cached responses with similar meaning using AI-powered matching
  </Step>
  <Step title="Intelligent Matching">
    Finds relevant cached responses even when questions are phrased differently
  </Step>
  <Step title="Smart Delivery">
    Returns cached responses in under 100ms with full compatibility
  </Step>
</Steps>

## Key Benefits

<CardGroup cols={4}>
  <Card title="Speed" icon="zap">
    **&lt;100ms**  
    Response times
  </Card>
  <Card title="Cost Savings" icon="dollar-sign">
    **60-80%**  
    Reduction for similar queries
  </Card>
  <Card title="Intelligence" icon="brain">
    **Understands meaning**  
    Not just exact matches
  </Card>
  <Card title="Reliability" icon="shield-check">
    **Success-only caching**  
    Never caches errors
  </Card>
</CardGroup>

## Real-World Examples

### Customer Support Queries

<Tabs>
<Tab title="Password Help">
**Original Query**: "How do I reset my password?"

**Semantic Matches** (all return the same cached response):
- "I forgot my password"
- "Password reset steps" 
- "Help me recover my account"
- "Can't log in - need new password"
- "Locked out of my account"
</Tab>

<Tab title="Technical Questions">
**Original Query**: "How to implement JWT authentication"

**Semantic Matches**:
- "JWT auth implementation guide"
- "Setting up JSON Web Token auth"
- "JWT authentication tutorial"
- "How do I add JWT to my app"
- "JSON Web Token setup steps"
</Tab>

<Tab title="General Inquiries">
**Original Query**: "What are your business hours?"

**Semantic Matches**:
- "When are you open?"
- "Office hours information"
- "What time do you close?"
- "Are you open on weekends?"
- "Store operating hours"
</Tab>
</Tabs>

## Cache Priority System

Adaptive checks caches in optimal order for best performance:

<Steps>
  <Step title="L1: Prompt Response Cache">
    **Microseconds**: Exact matches if explicitly enabled per request
  </Step>
  <Step title="L2: Semantic Cache">
    **Sub-100ms**: Similar meaning matches (enabled by default)
  </Step>
  <Step title="L3: Fresh Request">
    **Standard latency**: New API call to provider
  </Step>
</Steps>

## Configuration Options

### Default Behavior (Recommended)

Most applications work perfectly with default settings:

<CodeGroup>
```javascript JavaScript/Node.js
// Default - semantic cache enabled automatically
const completion = await openai.chat.completions.create({
  model: "",
  messages: [{ role: "user", content: "How do I reset my password?" }]
  // Semantic cache works automatically
});

console.log(`Cache tier: ${completion.usage.cache_tier}`);
```

```python Python
# Default - semantic cache enabled automatically  
completion = client.chat.completions.create(
    model="",
    messages=[{"role": "user", "content": "How do I reset my password?"}]
    # Semantic cache works automatically
)

print(f"Cache tier: {completion.usage.cache_tier}")
```
</CodeGroup>

### Custom Threshold Settings

<CodeGroup>
```javascript Strict Matching
// Higher threshold = stricter matching
const completion = await openai.chat.completions.create({
  model: "",
  messages: [{ role: "user", content: "Technical implementation question" }],
  model_router: {
    semantic_cache: {
      threshold: 0.9  // Higher = more precise matching
    }
  }
});
```

```javascript Loose Matching
// Lower threshold = broader matching  
const completion = await openai.chat.completions.create({
  model: "",
  messages: [{ role: "user", content: "General help question" }],
  model_router: {
    semantic_cache: {
      threshold: 0.75  // Lower = more flexible matching
    }
  }
});
```

```javascript Disable Caching
// Disable for real-time data
const completion = await openai.chat.completions.create({
  model: "",
  messages: [{ role: "user", content: "What's the current stock price?" }],
  model_router: {
    semantic_cache: {
      enabled: false  // Disable for time-sensitive content
    }
  }
});
```
</CodeGroup>

## Configuration Parameters

<ParamField body="model_router.semantic_cache" type="object">
  Configuration for semantic caching behavior
  
  <Expandable title="Properties">
    <ParamField body="enabled" type="boolean">
      Enable/disable semantic caching (default: true)
    </ParamField>
    
    <ParamField body="threshold" type="number">
      Similarity threshold from 0.0-1.0 (default: 0.85)
    </ParamField>
  </Expandable>
</ParamField>

## Similarity Threshold Guide

Choose the right threshold for your use case:

<CardGroup cols={3}>
  <Card title="Loose Matching" icon="arrows-left-right-to-line">
    **0.7 - 0.8**  
    FAQ systems, customer support, general inquiries
  </Card>
  <Card title="Balanced Matching" icon="balance-scale">
    **0.8 - 0.9** (Default)  
    Most applications, mixed content types
  </Card>
  <Card title="Strict Matching" icon="bullseye">
    **0.9+**  
    Technical docs, legal content, precise requirements
  </Card>
</CardGroup>

### Threshold Examples

<Tabs>
<Tab title="0.75 - Loose">
**Good for**: Customer support, FAQ systems

```javascript
"How do I cancel my subscription?" 
// Matches: "cancel membership", "stop billing", "end service"
```

**Pros**: High cache hit rate, good for varied user language  
**Cons**: May occasionally match unrelated queries
</Tab>

<Tab title="0.85 - Balanced">
**Good for**: Most applications (default setting)

```javascript
"How to implement user authentication?"
// Matches: "user login setup", "authentication guide", "sign-in system"
```

**Pros**: Good balance of accuracy and coverage  
**Cons**: May miss some loosely related queries
</Tab>

<Tab title="0.95 - Strict">
**Good for**: Technical documentation, legal content

```javascript
"JWT token validation in Node.js"
// Matches: "Node.js JWT validation", "validating JWT tokens Node"
```

**Pros**: Very precise matching, no false positives  
**Cons**: Lower cache hit rate, may miss paraphrases
</Tab>
</Tabs>

## Cache Performance Tracking

### Response Metadata

Every response includes cache performance information:

```json
{
  "id": "chatcmpl-abc123",
  "choices": [{"message": {"content": "To reset your password..."}}],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 25,
    "total_tokens": 40,
    "cache_tier": "semantic_similar"  // Cache performance indicator
  },
  "provider": "cached",
  "model": "cached-response"
}
```

### Cache Tier Values

<CardGroup cols={2}>
  <Card title="semantic_exact" icon="bullseye">
    **Perfect match**: Identical semantic meaning found
  </Card>
  <Card title="semantic_similar" icon="target">
    **Similar match**: Semantically related content found
  </Card>
  <Card title="undefined" icon="x">
    **No cache**: Fresh response from API provider
  </Card>
  <Card title="prompt_response" icon="database">
    **Explicit cache**: From prompt-response cache if enabled
  </Card>
</CardGroup>

## Performance Characteristics

<CardGroup cols={4}>
  <Card title="Hit Latency" icon="zap">
    **50-100ms**  
    Including embedding computation
  </Card>
  <Card title="Miss Overhead" icon="plus">
    **10-20ms**  
    Added for similarity analysis
  </Card>
  <Card title="Hit Rate" icon="percent">
    **40-60%**  
    Typical applications
  </Card>
  <Card title="Storage" icon="database">
    **AI-powered**  
    Embedding-based indexing
  </Card>
</CardGroup>

## Ideal Use Cases

### Perfect Fits

<CardGroup cols={2}>
  <Card title="Customer Support" icon="headset">
    **High hit rate**: Users ask similar questions in many different ways
  </Card>
  <Card title="Documentation Search" icon="book">
    **Consistent responses**: Same explanations for similar concepts
  </Card>
  <Card title="FAQ Systems" icon="question-circle">
    **Multiple phrasings**: Various ways to ask the same questions
  </Card>
  <Card title="Educational Content" icon="graduation-cap">
    **Concept explanations**: Similar topics with consistent answers
  </Card>
</CardGroup>

### When to Disable

<Warning>
Consider disabling semantic cache for time-sensitive or highly personalized content.
</Warning>

<CardGroup cols={2}>
  <Card title="Real-time Data" icon="clock">
    **Examples**: Stock prices, live sports scores, current weather
  </Card>
  <Card title="Personalized Content" icon="user">
    **Examples**: User-specific data, account information, personal history
  </Card>
  <Card title="Time-sensitive Info" icon="calendar">
    **Examples**: Breaking news, current events, recent updates
  </Card>
  <Card title="High-precision Content" icon="crosshairs">
    **Examples**: Legal advice, medical information, financial guidance
  </Card>
</CardGroup>

## Best Practices

### For Maximum Effectiveness

<Steps>
  <Step title="Use Default Settings">
    The 0.85 threshold works well for most applications
  </Step>
  <Step title="Monitor Hit Rates">
    Track `cache_tier` values to measure effectiveness
  </Step>
  <Step title="Adjust by Use Case">
    Lower thresholds for FAQ systems, higher for technical content
  </Step>
  <Step title="Test Different Thresholds">
    Experiment to find optimal settings for your specific use case
  </Step>
</Steps>

### Optimization Tips

<CardGroup cols={2}>
  <Card title="Content Strategy" icon="lightbulb">
    **Group similar topics**: Organize content to maximize cache hits
  </Card>
  <Card title="Threshold Tuning" icon="sliders">
    **Start with defaults**: Adjust based on hit rate and accuracy needs
  </Card>
  <Card title="Performance Monitoring" icon="chart-line">
    **Track metrics**: Monitor cache efficiency and response times
  </Card>
  <Card title="User Patterns" icon="users">
    **Analyze queries**: Understand common user question patterns
  </Card>
</CardGroup>

## Error Handling and Reliability

<Note>
**Graceful Degradation**: Semantic cache failures never interrupt your requests - they automatically fallback to fresh API calls.
</Note>

### Failure Scenarios

<CardGroup cols={2}>
  <Card title="Embedding Service Issues" icon="brain">
    **Automatic fallback** to fresh requests without semantic matching
  </Card>
  <Card title="Cache Storage Problems" icon="database">
    **Transparent handling** - requests proceed normally
  </Card>
  <Card title="Similarity Computation Errors" icon="calculator">
    **Skip matching** and proceed with standard routing
  </Card>
  <Card title="Network Issues" icon="wifi">
    **Retry logic** with fallback to direct API calls
  </Card>
</CardGroup>

## Monitoring and Analytics

Track semantic cache performance in your [Adaptive dashboard](https://www.llmadaptive.uk/dashboard):

- **Cache hit rates** and trends over time
- **Similarity threshold effectiveness** for your content
- **Cost savings** achieved through semantic matching
- **Response time improvements** from cached responses
- **Cache efficiency** by content type and user patterns

## Technical Implementation

### Under the Hood

<Accordion title="Technical Details">

**Embedding Generation**
- Uses state-of-the-art sentence transformers
- Generates high-dimensional semantic representations
- Optimized for speed and accuracy

**Similarity Computation**  
- Cosine similarity between embedding vectors
- Configurable threshold-based matching
- Fast vector operations for real-time performance

**Storage & Retrieval**
- Efficient vector indexing and search
- Deferred caching after successful responses
- Automatic cache warming and optimization

**Error Resilience**
- Multiple fallback layers for reliability
- Success-only caching prevents error propagation
- Graceful degradation under any failure scenario

</Accordion>

## Next Steps

<CardGroup cols={2}>
  <Card title="Prompt Response Cache" href="/features/prompt-response-cache" icon="clock">
    Learn about the fastest caching layer for identical requests
  </Card>
  <Card title="Performance Overview" href="/features/performance" icon="gauge-high">
    Understand all performance optimization features
  </Card>
</CardGroup>