---
title: "Zero Completion Insurance"
description: "Automatic protection from charges on failed or empty responses"
icon: "shield-check"
---

Adaptive's zero completion insurance automatically protects you from being charged for failed requests or responses with no output tokens. When responses are empty or encounter errors, you pay nothing - even if underlying providers charge for processing.

## How It Works

<Steps>
  <Step title="Request Monitoring">
    Every response is automatically analyzed for completion tokens and status
  </Step>
  <Step title="Failure Detection">
    Identifies responses with zero output tokens and blank or error finish reasons
  </Step>
  <Step title="Automatic Protection">
    Credits are not deducted from your account when protection criteria are met
  </Step>
  <Step title="Cost Absorption">
    Adaptive absorbs provider costs for protected requests at no charge to you
  </Step>
</Steps>

## Protection Criteria

Zero completion insurance automatically applies when responses meet **either** of these conditions:

<CardGroup cols={2}>
  <Card title="Zero Output + Blank Finish" icon="circle-xmark">
    **Response has zero completion tokens** AND **finish reason is blank/null**

    Common scenarios: Provider timeouts, processing errors, system failures
  </Card>
  <Card title="Error Finish Reason" icon="exclamation-triangle">
    **Response has an error finish reason** regardless of token count

    Common scenarios: Content policy violations, rate limits, service unavailable
  </Card>
</CardGroup>

## Real Examples

<Tabs>
<Tab title="Provider Timeout">
**Request**: "Write a detailed analysis of quantum computing"  
**Response**: Empty (provider timeout)  
**Finish Reason**: null  
**Your Cost**: **$0.00** (protected)  
**Without Insurance**: $0.12 for prompt processing
</Tab>

<Tab title="Rate Limit Hit">
**Request**: "Hello, how are you?"  
**Response**: Error message  
**Finish Reason**: "rate_limit_exceeded"  
**Your Cost**: **$0.00** (protected)  
**Without Insurance**: $0.05 for prompt processing
</Tab>

<Tab title="Content Filter">
**Request**: Inappropriate content request  
**Response**: "Content blocked by safety filters"  
**Finish Reason**: "content_filter"  
**Your Cost**: **$0.00** (protected)  
**Without Insurance**: $0.08 for prompt processing
</Tab>
</Tabs>

## Automatic Coverage

<CardGroup cols={3}>
  <Card title="Always Enabled" icon="toggle-on">
    **No configuration required** - protection is automatically active for all accounts
  </Card>
  <Card title="All Models" icon="grid">
    **Universal coverage** across all providers and model types without exceptions
  </Card>
  <Card title="Zero Cost" icon="dollar-sign">
    **Completely free** - no additional fees or charges for insurance coverage
  </Card>
</CardGroup>

## Coverage Examples

### Protected Scenarios

These response types are automatically covered at no cost:

<CodeGroup>
```json Empty Response
{
  "choices": [{
    "message": {"content": ""},
    "finish_reason": null
  }],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 0,  // Zero output tokens
    "total_tokens": 15
  }
}
// Cost: $0.00 (protected)
```

```json Error Response
{
  "choices": [{
    "message": {"content": "Request failed due to rate limiting"},
    "finish_reason": "rate_limit_exceeded"  // Error finish reason
  }],
  "usage": {
    "prompt_tokens": 8,
    "completion_tokens": 7,
    "total_tokens": 15
  }
}
// Cost: $0.00 (protected)
```
</CodeGroup>

### Normal Billing

These responses are billed normally as they contain successful completions:

<CodeGroup>
```json Successful Response
{
  "choices": [{
    "message": {"content": "Hello! How can I help you today?"},
    "finish_reason": "stop"  // Normal completion
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,  // Has output tokens
    "total_tokens": 21
  }
}
// Cost: Normal billing applies
```
</CodeGroup>

## Viewing Protected Requests

### Dashboard Activity

In your [Adaptive dashboard](https://www.llmadaptive.uk/dashboard), protected requests are clearly marked:

<CardGroup cols={2}>
  <Card title="Zero Cost Display" icon="eye">
    **Credit Deduction**: Shows $0.00 for protected requests
  </Card>
  <Card title="Protection Badge" icon="shield">
    **Visual Indicator**: Protected requests display insurance badge
  </Card>
</CardGroup>

### Response Metadata

Protected requests include additional metadata in the response:

```json
{
  "insurance": {
    "protected": true,           // Request was protected
    "reason": "zero_completion", // Why it was protected
    "original_cost": 0.08,       // What you would have paid
    "savings": 0.08              // Amount saved
  }
}
```

## Insurance Benefits

<CardGroup cols={4}>
  <Card title="Risk-Free Testing" icon="flask">
    **Experiment freely** without fear of charges for failed requests
  </Card>
  <Card title="Cost Predictability" icon="calculator">
    **Budget control** - only pay for successful completions
  </Card>
  <Card title="Provider Reliability" icon="shield-check">
    **Protection from outages** - no charges during service disruptions
  </Card>
  <Card title="Development Safety" icon="code">
    **Safe debugging** - test requests without unexpected costs
  </Card>
</CardGroup>

## Comparison with Other Providers

<Note>
Most LLM providers charge for prompt processing regardless of response success. Adaptive is unique in providing comprehensive zero completion insurance.
</Note>

| Provider | Failed Request Charges | Empty Response Charges | Error State Charges |
|----------|----------------------|----------------------|-------------------|
| **Adaptive** | **$0.00** | **$0.00** | **$0.00** |
| OpenAI | Prompt tokens charged | Prompt tokens charged | Prompt tokens charged |
| Anthropic | Prompt tokens charged | Prompt tokens charged | Prompt tokens charged |
| Google AI | Prompt tokens charged | Prompt tokens charged | Prompt tokens charged |
| Other APIs | Prompt tokens charged | Prompt tokens charged | Prompt tokens charged |

## FAQ

<Accordion title="Does insurance affect my API usage limits?">
No, zero completion insurance does not count against your API rate limits or quotas. Protected requests are tracked separately and do not impact your usage calculations.
</Accordion>

<Accordion title="What happens during provider outages?">
During widespread provider outages, all requests that fail due to service unavailability are automatically protected. You won't be charged for any requests during outage periods, regardless of duration.
</Accordion>

<Accordion title="Can I disable zero completion insurance?">
No, insurance cannot be disabled as it only benefits users by preventing unwanted charges. There are no downsides to having this protection always active.
</Accordion>

## Best Practices

<CardGroup cols={2}>
  <Card title="Test Freely" icon="rocket">
    **Experiment confidently** knowing failed requests won't generate unexpected charges
  </Card>
  <Card title="Monitor Usage" icon="chart-line">
    **Track protection rates** in your dashboard to understand request patterns
  </Card>
</CardGroup>

## Implementation

Zero completion insurance requires no code changes - it works automatically with your existing integrations:

```javascript
// Normal request - insurance automatically active
const completion = await openai.chat.completions.create({
  model: "gpt-4",
  messages: [{ role: "user", content: "Hello!" }]
});

// Check if request was protected
if (completion.insurance?.protected) {
  console.log(`Saved $${completion.insurance.savings} on failed request`);
}
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Cost Monitoring" href="/dashboard" icon="chart-mixed">
    View your insurance savings and protected request statistics
  </Card>
  <Card title="Provider Resiliency" href="/features/provider-resiliency" icon="shield">
    Learn about automatic failover and reliability features
  </Card>
</CardGroup>
