---
title: 'Quickstart'
description: 'Get started with Adaptive in under 5 minutes'
icon: "rocket"
---

Get started with Adaptive by changing one line of code. No complex setup required.

## Step 1: Get Your API Key

<Steps>
  <Step title="Sign Up">
    Create a free account at [llmadaptive.uk](https://www.llmadaptive.uk)
  </Step>
  <Step title="Generate Key">
    Generate your API key from the dashboard
  </Step>
</Steps>

## Step 2: Install SDK (Optional)

<Tabs>
<Tab title="JavaScript/Node.js">
<CodeGroup>
```bash npm
npm install openai
```

```bash yarn
yarn add openai
```

```bash pnpm
pnpm add openai
```
</CodeGroup>
</Tab>

<Tab title="Python">
<CodeGroup>
```bash pip
pip install openai
```

```bash poetry
poetry add openai
```

```bash conda
conda install openai
```
</CodeGroup>
</Tab>

<Tab title="cURL">
No installation required - cURL is available on most systems.
</Tab>
</Tabs>

## Step 3: Make Your First Request

Choose your preferred language and framework:

<Tabs>
<Tab title="OpenAI SDK">

<CodeGroup>
```javascript JavaScript/Node.js
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'your-adaptive-api-key',
  baseURL: 'https://www.llmadaptive.uk/api/v1'
});

const response = await client.chat.completions.create({
  model: '', // Leave empty for intelligent routing
  messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.choices[0].message.content);
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="your-adaptive-api-key",
    base_url="https://www.llmadaptive.uk/api/v1"
)

response = client.chat.completions.create(
    model="", # Leave empty for intelligent routing
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```bash cURL
curl https://www.llmadaptive.uk/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-adaptive-api-key" \
  -d '{
    "model": "",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```
</CodeGroup>

</Tab>

<Tab title="Anthropic SDK">

<CodeGroup>
```javascript JavaScript/Node.js
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: 'your-adaptive-api-key',
  baseURL: 'https://www.llmadaptive.uk/api/v1'
});

const response = await client.messages.create({
  model: '', // Leave empty for intelligent routing
  max_tokens: 1000,
  messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.content[0].text);
```

```python Python
import anthropic

client = anthropic.Anthropic(
    api_key="your-adaptive-api-key",
    base_url="https://www.llmadaptive.uk/api/v1"
)

response = client.messages.create(
    model="", # Leave empty for intelligent routing
    max_tokens=1000,
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.content[0].text)
```

```bash cURL
curl https://www.llmadaptive.uk/api/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-adaptive-api-key" \
  -H "anthropic-version: 2023-06-01" \
  -d '{
    "model": "",
    "max_tokens": 1000,
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```
</CodeGroup>

</Tab>

<Tab title="Vercel AI SDK">

<CodeGroup>
```javascript Basic Text Generation
import { openai } from '@ai-sdk/openai';
import { generateText } from 'ai';

const { text } = await generateText({
  model: openai('', {
    baseURL: 'https://www.llmadaptive.uk/api/v1',
    apiKey: 'your-adaptive-api-key'
  }),
  prompt: 'Hello!'
});

console.log(text);
```

```javascript Streaming
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

const { textStream } = await streamText({
  model: openai('', {
    baseURL: 'https://www.llmadaptive.uk/api/v1',
    apiKey: 'your-adaptive-api-key'
  }),
  prompt: 'Write a story about AI'
});

for await (const delta of textStream) {
  process.stdout.write(delta);
}
```

```javascript React Components
import { useChat } from 'ai/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: '/api/chat', // Your API route
    initialMessages: [{ role: 'system', content: 'Hello!' }]
  });

  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>
          {m.role}: {m.content}
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
      </form>
    </div>
  );
}
```
</CodeGroup>

</Tab>

<Tab title="LangChain">

<CodeGroup>
```javascript JavaScript/Node.js
import { ChatOpenAI } from '@langchain/openai';

const model = new ChatOpenAI({
  openAIApiKey: 'your-adaptive-api-key',
  configuration: {
    baseURL: 'https://www.llmadaptive.uk/api/v1'
  },
  modelName: '' // Leave empty for intelligent routing
});

const response = await model.invoke('Hello!');
console.log(response.content);
```

```python Python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    openai_api_key="your-adaptive-api-key",
    openai_api_base="https://www.llmadaptive.uk/api/v1",
    model_name="" # Leave empty for intelligent routing
)

response = model.invoke("Hello!")
print(response.content)
```

```python Chains
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

model = ChatOpenAI(
    openai_api_key="your-adaptive-api-key",
    openai_api_base="https://www.llmadaptive.uk/api/v1",
    model_name=""
)

prompt = PromptTemplate(
    input_variables=["topic"],
    template="Write a brief summary about {topic}"
)

chain = LLMChain(llm=model, prompt=prompt)
result = chain.run(topic="artificial intelligence")
print(result)
```
</CodeGroup>

</Tab>
</Tabs>

## Key Features

<CardGroup cols={2}>
  <Card title="Intelligent Routing" icon="brain">
    Leave `model` empty and let our AI choose the optimal provider for your request
  </Card>
  <Card title="Cost Savings" icon="dollar-sign">
    Save 60-80% on AI costs with automatic model selection
  </Card>
  <Card title="6+ Providers" icon="network-wired">
    Access OpenAI, Anthropic, Google, Groq, DeepSeek, and Grok
  </Card>
  <Card title="Drop-in Replacement" icon="plug">
    Works with existing OpenAI and Anthropic SDK code
  </Card>
</CardGroup>

## Example Response

<CodeGroup>
```json OpenAI Format
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-3.5-turbo",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! I'm ready to help you."
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 10,
    "total_tokens": 15
  },
  "provider": "gemini",
  "cache_tier": "none"
}
```

```json Anthropic Format
{
  "id": "msg_abc123",
  "type": "message",
  "role": "assistant",
  "content": [{
    "type": "text",
    "text": "Hello! I'm ready to help you."
  }],
  "model": "claude-3-haiku",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 5,
    "output_tokens": 10
  },
  "provider": "anthropic",
  "cache_tier": "none"
}
```
</CodeGroup>

<Note>
Adaptive returns standard OpenAI or Anthropic-compatible responses with additional metadata like `provider` and `cache_tier` to show which model was selected and performance information.
</Note>

## Testing Your Integration

<Steps>
  <Step title="Send Test Request">
    Run your code with a simple message like "Hello!" to verify the connection
  </Step>
  <Step title="Check Response">
    Confirm you receive a response and check the `provider` field to see which model was selected
  </Step>
  <Step title="Monitor Dashboard">
    View request logs and analytics in your [Adaptive dashboard](https://www.llmadaptive.uk/dashboard)
  </Step>
</Steps>

## Next Steps

<CardGroup cols={2}>
  <Card title="Advanced Features" href="/features/intelligent-routing" icon="lightbulb">
    Learn about intelligent routing and semantic caching
  </Card>
  <Card title="Integration Guides" href="/integrations/openai-sdk" icon="book">
    Detailed guides for each SDK and framework
  </Card>
  <Card title="API Reference" href="/api-reference/chat-completions" icon="terminal">
    Complete API documentation with all parameters
  </Card>
  <Card title="Code Examples" href="/examples/basic-chat" icon="code">
    Working examples for common use cases
  </Card>
</CardGroup>

## Need Help?

<CardGroup cols={2}>
  <Card title="Troubleshooting" href="/troubleshooting" icon="wrench">
    Common issues and their solutions
  </Card>
  <Card title="Support" href="https://www.llmadaptive.uk/support" icon="life-ring">
    Get help from our team
  </Card>
</CardGroup>