---
title: 'Quickstart'
description: 'Get started with Adaptive in under 5 minutes'
icon: "rocket"
---

Get started with Adaptive by changing one line of code. No complex setup required.

## Step 1: Get Your API Key

<Steps>
  <Step title="Sign Up">
    [Create a free account](https://www.llmadaptive.uk/sign-up?redirect_url=/api-platform/orgs) to get started
  </Step>
  <Step title="Generate Key">
    Generate your API key from the dashboard
  </Step>
</Steps>

## Step 2: Install SDK

<CodeGroup>
```bash npm
npm install openai
```

```bash pip
pip install openai
```
</CodeGroup>

## Step 3: Make Your First Request

<CodeGroup>
```javascript JavaScript/Node.js
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'your-adaptive-api-key',
  baseURL: 'https://api.llmadaptive.uk/v1'
});

const response = await client.chat.completions.create({
  model: '', // Leave empty for intelligent routing
  messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.choices[0].message.content);
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="your-adaptive-api-key",
    base_url="https://api.llmadaptive.uk/v1"
)

response = client.chat.completions.create(
    model="", # Leave empty for intelligent routing
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```bash cURL
curl https://api.llmadaptive.uk/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-adaptive-api-key" \
  -d '{
    "model": "",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```
</CodeGroup>

## Key Features

<CardGroup cols={2}>
  <Card title="Model Routing" icon="brain">
    Leave `model` empty for automatic provider selection
  </Card>
  <Card title="Cost Savings" icon="dollar-sign">
    Save 60-90% with smart model routing
  </Card>
  <Card title="Drop-in Replacement" icon="plug">
    Works with existing OpenAI SDK code
  </Card>
  <Card title="6+ Providers" icon="network-wired">
    Access OpenAI, Anthropic, Google, Groq, DeepSeek, and Grok
  </Card>
</CardGroup>

## Example Response

<CodeGroup>
```json OpenAI Format
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-3.5-turbo",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! I'm ready to help you."
    },
    "finish_reason": "stop"
  }],
   "usage": {
     "prompt_tokens": 5,
     "completion_tokens": 10,
     "total_tokens": 15
   }
}
```

```json Anthropic Format
{
  "id": "msg_abc123",
  "type": "message",
  "role": "assistant",
  "content": [{
    "type": "text",
    "text": "Hello! I'm ready to help you."
  }],
   "model": "anthropic/claude-4-5-sonnet",
  "stop_reason": "end_turn",
   "usage": {
     "input_tokens": 5,
     "output_tokens": 10
   }
}
```
</CodeGroup>

<Note>
Adaptive returns standard OpenAI or Anthropic-compatible responses with additional metadata to show which model was selected and performance information.
</Note>

## Testing Your Integration

<Steps>
  <Step title="Send Test Request">
    Run your code with a simple message like "Hello!" to verify the connection
  </Step>
  <Step title="Check Response">
     Confirm you receive a response and check the model field to see which model was selected
  </Step>
  <Step title="Monitor Dashboard">
    View request logs and analytics in your [Adaptive dashboard](https://www.llmadaptive.uk/dashboard)
  </Step>
</Steps>

## Next Steps

<CardGroup cols={2}>
  <Card title="API Reference" href="/api-reference/chat-completions" icon="terminal">
    Complete API documentation
  </Card>
  <Card title="Integration Guides" href="/integrations/openai-sdk" icon="book">
    Detailed SDK guides
  </Card>
  <Card title="Examples" href="/examples/basic-chat" icon="code">
    Working code examples
  </Card>
  <Card title="Troubleshooting" href="/troubleshooting" icon="wrench">
    Common issues and solutions
  </Card>
</CardGroup>