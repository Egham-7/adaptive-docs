---
title: 'Chat Completions'
api: 'POST https://api.llmadaptive.uk/v1/chat/completions'
description: 'OpenAI-compatible completions with intelligent routing'
---

<Note>
Use `model: "adaptive/auto"` for automatic cost optimization and model selection
</Note>

## Quick Start

<CodeGroup>
```bash cURL
curl https://api.llmadaptive.uk/v1/chat/completions \
  -H "Authorization: Bearer apk_123456" \
  -d '{
    "model": "adaptive/auto",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

```python Python
import openai

client = openai.OpenAI(
    api_key="apk_123456",
    base_url="https://api.llmadaptive.uk/v1"
)

response = client.chat.completions.create(
    model="adaptive/auto",  # Auto-select best model
    messages=[{"role": "user", "content": "Hello!"}]
)
```
</CodeGroup>

## Parameters

<ParamField body="model" type="string" required>
  Use `"adaptive/auto"` for auto-selection or specify model like `"openai/gpt-4"`
</ParamField>

<ParamField body="messages" type="array" required>
  Message array with `role` and `content` fields
</ParamField>

<ParamField body="temperature" type="number">
  Controls randomness (0-2). Default: 1
</ParamField>

<ParamField body="max_completion_tokens" type="integer">
  Maximum tokens to generate
</ParamField>

<ParamField body="stream" type="boolean">
  Enable streaming. Default: false
</ParamField>

<ParamField body="model_router" type="object">
  Control routing: `{"cost_bias": 0.5, "models": ["openai/gpt-4"]}`
</ParamField>

<ParamField body="fallback" type="object">
  Provider fallback: `{"mode": "sequential"}`
</ParamField>
</ParamField>

<ParamField body="presence_penalty" type="number">
  Penalty for token presence. Range: -2.0 to 2.0. Default: `0`
</ParamField>

<ParamField body="n" type="integer">
  Number of chat completion choices to generate. Default: `1`
</ParamField>

<ParamField body="seed" type="integer">
  Seed for deterministic sampling. Helps ensure reproducible results.
</ParamField>

<ParamField body="stop" type="string | array">
  Up to 4 sequences where the API will stop generating tokens.
</ParamField>

<ParamField body="user" type="string">
  Unique identifier for end-user to help detect abuse and improve caching.
</ParamField>

### Advanced Parameters

<ParamField body="logprobs" type="boolean">
  Whether to return log probabilities of output tokens. Default: `false`
</ParamField>

<ParamField body="top_logprobs" type="integer">
  Number of most likely tokens to return at each position (0-20). Requires `logprobs: true`.
</ParamField>

<ParamField body="logit_bias" type="object">
  Modify likelihood of specified tokens. Maps token IDs to bias values (-100 to 100).
</ParamField>

<ParamField body="response_format" type="object">
  Format for model output. Supports JSON schema for structured outputs.
  
  <Expandable title="Response Format Options">
    <ParamField body="type" type="string">
      Either `json_object` or `json_schema`
    </ParamField>
    
    <ParamField body="json_schema" type="object">
      JSON schema definition when using `json_schema` type
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="service_tier" type="string">
  Latency tier for processing. Options: `auto`, `default`, `flex`
</ParamField>

<ParamField body="store" type="boolean">
  Whether to store output for model distillation or evals. Default: `false`
</ParamField>

<ParamField body="metadata" type="object">
  Set of 16 key-value pairs for storing additional information about the request.
</ParamField>

### Audio and Multimodal

<ParamField body="modalities" type="array">
  Output types to generate. Options: `["text"]`, `["audio"]`, or `["text", "audio"]`
</ParamField>

<ParamField body="audio" type="object">
  Parameters for audio output when `modalities` includes `"audio"`.
</ParamField>

### Reasoning Models (o-series)

<ParamField body="reasoning_effort" type="string">
  **o-series models only** - Effort level for reasoning: `low`, `medium`, or `high`
</ParamField>

### Function Calling

<ParamField body="tools" type="array">
  Array of tool definitions for function calling. Maximum 128 functions.
  
  <Expandable title="Tool Definition">
    <ParamField body="type" type="string">
      Tool type, currently only `function` supported
    </ParamField>
    
    <ParamField body="function" type="object">
      Function definition with name, description, and parameters schema
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="tool_choice" type="string | object">
  Controls tool usage: `none`, `auto`, `required`, or specific tool selection
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean">
  Whether to enable parallel function calling. Default: `true`
</ParamField>

<ParamField body="function_call" type="string | object">
  **Deprecated** - Use `tool_choice` instead. Controls function calling behavior.
</ParamField>

### Web Search

<ParamField body="web_search_options" type="object">
  Options for web search tool functionality.
</ParamField>

### Streaming Options

<ParamField body="stream_options" type="object">
  Additional options for streaming responses.
  
  <Expandable title="Stream Options">
    <ParamField body="include_usage" type="boolean">
      Whether to include usage statistics in streaming response
    </ParamField>
  </Expandable>
</ParamField>

### Prediction and Caching

<ParamField body="prediction" type="object">
  Static predicted output content for regeneration scenarios.
</ParamField>

### Adaptive-Specific Parameters

<ParamField body="model_router" type="object">
  Configuration for intelligent routing and provider selection.
  
  <Expandable title="Model Router Config">
    <ParamField body="models" type="ModelCapability[]">
      Array of model capabilities to consider for routing. Can be simplified or detailed:
      
      **Simple formats:**
      - `"openai/gpt-5-mini"` - Use specific OpenAI model
      - `"anthropic/claude-sonnet-4-5"` - Use specific Anthropic model
      
      **Custom models require all parameters:**
      
      <Expandable title="Model Capability Object">
        <ParamField body="provider" type="string" required>
          Provider name: `"openai"`, `"anthropic"`, `"gemini"`, `"z-ai"`
        </ParamField>
        
        <ParamField body="model_name" type="string">
          Specific model identifier (e.g., `"gpt-5-mini"`, `"claude-sonnet-4-5"`). **Required for specific model selection**
        </ParamField>
        
        <ParamField body="cost_per_1m_input_tokens" type="number">
          Cost per 1 million input tokens in USD.
        </ParamField>
        
        <ParamField body="cost_per_1m_output_tokens" type="number">
          Cost per 1 million output tokens in USD.
        </ParamField>

        <ParamField body="context_length" type="integer">
          Maximum context window size in tokens. Replaces deprecated `max_context_tokens`.
        </ParamField>

        <ParamField body="max_completion_tokens" type="integer">
          Maximum output tokens the model can generate. Replaces deprecated `max_output_tokens`.
        </ParamField>

        <ParamField body="supported_parameters" type="array">
          List of supported API parameters (e.g., ["temperature", "top_p", "tools"]). Replaces deprecated `supports_tool_calling` boolean.
        </ParamField>
        
        <ParamField body="description" type="string">
          Human-readable description of the model
        </ParamField>
        
        <ParamField body="languages_supported" type="string[]">
          Array of supported language codes
        </ParamField>
        
        <ParamField body="model_size_params" type="string">
          Model size information (e.g., `"7B"`, `"70B"`)
        </ParamField>
        
        <ParamField body="latency_tier" type="string">
          Expected latency: `"low"`, `"medium"`, `"high"`
        </ParamField>
        
        <ParamField body="task_type" type="string">
          Optimal task type: `"Open QA"`, `"Closed QA"`, `"Summarization"`, `"Text Generation"`, `"Code Generation"`, `"Chatbot"`, `"Classification"`, `"Rewrite"`, `"Brainstorming"`, `"Extraction"`, `"Other"`
        </ParamField>
        
        <ParamField body="complexity" type="string">
          Model complexity tier: `"low"`, `"medium"`, `"high"`
        </ParamField>
      </Expandable>
    </ParamField>
    
## Response

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "openai/gpt-4",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```
