---
title: "Gemini CLI Integration"
description: "Configure Gemini CLI with Adaptive's intelligent routing to automatically select the optimal Gemini model for each task"
icon: "sparkles"
---

Configure Gemini CLI to use Adaptive's intelligent routing infrastructure that automatically selects the optimal Google Gemini model for each task.

<Tip>
**Intelligent Gemini model selection** with automatic routing. Works as a drop-in replacement for Gemini CLI's API backend, selecting between Gemini 2.5 Pro, Flash, and Flash Lite based on task complexity with cost optimization built-in.
</Tip>

## Benefits of Using Gemini CLI with Adaptive

When you integrate Gemini CLI with Adaptive, you unlock powerful capabilities:

- **Intelligent Model Selection**: Adaptive automatically selects the optimal Gemini model (2.5 Pro, 2.5 Flash, or 2.5 Flash Lite) based on your task complexity
- **Cost Optimization**: Automatically routes simple tasks to Flash Lite, moderate tasks to Flash, and complex tasks to Pro, optimizing costs without sacrificing quality
- **Higher Reliability**: Automatic fallbacks and retry logic ensure consistent responses
- **Usage Analytics**: Monitor model usage, costs, and performance in real-time
- **Simplified Configuration**: Single API key for all Gemini model variants

## Get Your Adaptive API Key

Visit [llmadaptive.uk](https://www.llmadaptive.uk) to create an account and generate your API key.

## Quick Setup

<Steps>
  <Step title="Run Automated Installer" icon="rocket">
    ```bash
    curl -fsSL https://raw.githubusercontent.com/Egham-7/adaptive/main/scripts/installers/gemini-cli.sh | bash
    ```
    The installer will automatically:
    - Install Gemini CLI if not present (via npm)
    - Configure environment variables for Adaptive routing
    - Add configuration to your shell profile (~/.bashrc, ~/.zshrc, etc.)
    - Verify the installation
  </Step>
  <Step title="Verify Configuration" icon="check">
    ```bash
    gemini --version
    echo $GEMINI_API_KEY
    echo $GOOGLE_GEMINI_BASE_URL
    ```
  </Step>
  <Step title="Start Using" icon="play">
    ```bash
    gemini "explain quantum computing"
    ```
    Adaptive will automatically route your request to the optimal Gemini model.
  </Step>
</Steps>

## Manual Installation

If you prefer to set up Gemini CLI manually or need more control over the installation process:

### Step 1: Install Gemini CLI

```bash
npm install -g @google/gemini-cli
```

### Step 2: Configure Environment Variables

<CodeGroup>
```bash Bash/Zsh (~/.bashrc or ~/.zshrc)
# Gemini CLI with Adaptive LLM API Configuration
export GEMINI_API_KEY="your-adaptive-api-key-here"
export GOOGLE_GEMINI_BASE_URL="https://www.llmadaptive.uk/api/v1beta"
```

```fish Fish Shell (~/.config/fish/config.fish)
# Gemini CLI with Adaptive LLM API Configuration
set -x GEMINI_API_KEY "your-adaptive-api-key-here"
set -x GOOGLE_GEMINI_BASE_URL "https://www.llmadaptive.uk/api/v1beta"
```
</CodeGroup>

### Step 3: Apply Configuration

```bash
# For Bash/Zsh
source ~/.bashrc  # or ~/.zshrc

# For Fish
source ~/.config/fish/config.fish

# Or restart your terminal
```

### Step 4: Verify Installation

```bash
gemini --version
gemini "test connection"
```

## Alternative Setup Methods

<CodeGroup>
```bash Environment Variable Method
export ADAPTIVE_API_KEY='your-api-key-here'
curl -fsSL https://raw.githubusercontent.com/Egham-7/adaptive/main/scripts/installers/gemini-cli.sh | bash
# The installer will automatically configure your shell
```

```bash Interactive Installation
curl -o gemini-cli.sh https://raw.githubusercontent.com/Egham-7/adaptive/main/scripts/installers/gemini-cli.sh
chmod +x gemini-cli.sh
./gemini-cli.sh
# Follow the interactive prompts
```

```bash Custom Model Configuration
export ADAPTIVE_API_KEY='your-api-key-here'
export ADAPTIVE_MODEL='gemini-2.5-pro'  # Optional: specify default model
curl -fsSL https://raw.githubusercontent.com/Egham-7/adaptive/main/scripts/installers/gemini-cli.sh | bash
```
</CodeGroup>

## Advanced Configuration

### Specifying Gemini Models

Configure which Gemini model to use by default:

<CodeGroup>
```bash Gemini 2.5 Pro
# Use Gemini 2.5 Pro for complex tasks
export GEMINI_MODEL='gemini:gemini-2.5-pro'
gemini "write a complex algorithm"
```

```bash Gemini 2.5 Flash
# Use Gemini 2.5 Flash for moderate tasks
export GEMINI_MODEL='gemini:gemini-2.5-flash'
gemini "explain this code"
```

```bash Gemini 2.5 Flash Lite
# Use Gemini 2.5 Flash Lite for simple tasks
export GEMINI_MODEL='gemini:gemini-2.5-flash-lite'
gemini "what is JavaScript?"
```

```bash Intelligent Routing (Recommended)
# Let Adaptive choose the optimal Gemini model
export GEMINI_MODEL=''
gemini "complex reasoning task"
```
</CodeGroup>

### Model Selection

When `GEMINI_MODEL` is not set or empty, Adaptive intelligently selects the best Gemini model for each task based on:
- **Task complexity**: Analyzes prompt complexity to select the optimal model
- **Performance requirements**: Matches model capabilities to task needs
- **Cost optimization**: Balances performance and cost automatically
- **Availability**: Automatic fallback if a model is unavailable

### Available Gemini Models

| Model | Best For | Speed | Cost |
|-------|----------|-------|------|
| `gemini-2.5-pro` | Complex reasoning, deep analysis | Slower | Higher |
| `gemini-2.5-flash` | Moderate tasks, balanced performance | Fast | Medium |
| `gemini-2.5-flash-lite` | Simple tasks, quick responses | Fastest | Lowest |

## Usage Examples

<CodeGroup>
```bash Interactive Chat
# Start interactive chat session
gemini

# Or with a specific prompt
gemini "help me debug this code"
```

```bash Code Assistance
# Generate code
gemini "create a React component for user authentication"

# Explain code
gemini "explain how async/await works in JavaScript"

# Debug code
gemini "why is my Python script throwing a TypeError?"
```

```bash Quick Tasks
# Get quick answers
gemini "what's the difference between let and const?"

# Generate documentation
gemini "write documentation for this API endpoint"

# Code review
gemini "review this function for potential bugs"
```
</CodeGroup>

## Troubleshooting

<AccordionGroup>
<Accordion title="Installation Issues" icon="wrench">
**Problem**: Gemini CLI installation fails

**Solutions**:
- Ensure Node.js 18+ is installed: `node --version`
- Install Node.js if needed:
  ```bash
  # Using nvm (recommended)
  curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash
  nvm install 22
  ```
- Check npm permissions: `npm config get prefix`
- Try with sudo (not recommended): `sudo npm install -g @google/gemini-cli`
</Accordion>

<Accordion title="Authentication Errors" icon="key">
**Problem**: "Unauthorized" or "Invalid API key" errors

**Solutions**:
1. Verify your API key at [llmadaptive.uk/dashboard](https://www.llmadaptive.uk/dashboard)
2. Check environment variables are set:
   ```bash
   echo $GEMINI_API_KEY
   echo $GOOGLE_GEMINI_BASE_URL
   ```
3. Ensure variables are exported in your shell config:
   ```bash
   # Bash/Zsh
   source ~/.bashrc  # or ~/.zshrc

   # Fish
   source ~/.config/fish/config.fish
   ```
4. Restart your terminal if changes were made to shell config
5. Verify the base URL is correct: `https://www.llmadaptive.uk/api/v1`
</Accordion>

<Accordion title="Connection Errors" icon="network-wired">
**Problem**: Cannot connect to Adaptive API

**Solutions**:
- Check internet connectivity
- Verify base URL is correct: `echo $GOOGLE_GEMINI_BASE_URL`
- Test API directly:
  ```bash
  curl -X POST https://www.llmadaptive.uk/api/v1/chat/completions \
    -H "Authorization: Bearer $GEMINI_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "gemini-2.5-pro",
      "messages": [{"role": "user", "content": "Hello"}]
    }'
  ```
- Check if your network/firewall blocks the API endpoint
</Accordion>

<Accordion title="Model Routing Issues" icon="route">
**Problem**: Requests not routing to expected models

**Solutions**:
1. Check if model alias is configured (if using advanced routing)
2. Verify your Adaptive proxy configuration
3. Review model names in your requests
4. Check Adaptive dashboard for routing logs
5. Clear the `ADAPTIVE_MODEL` environment variable for intelligent routing:
   ```bash
   unset ADAPTIVE_MODEL
   ```
</Accordion>

<Accordion title="Performance Issues" icon="gauge-high">
**Problem**: Slow response times or timeouts

**Solutions**:
- Check Adaptive dashboard for provider status
- Verify rate limits aren't exceeded
- Consider using load balancing across multiple providers
- Check your internet connection speed
- Review model selectionâ€”some models are faster than others
</Accordion>
</AccordionGroup>

## Uninstallation

If you need to remove Gemini CLI or revert to Google's API:

<Steps>
  <Step title="Remove Gemini CLI">
    ```bash
    npm uninstall -g @google/gemini-cli
    ```
  </Step>
  <Step title="Remove Environment Variables">
    Edit your shell config file and remove these lines:
    ```bash
    # Gemini CLI with Adaptive LLM API Configuration
    export GEMINI_API_KEY="..."
    export GOOGLE_GEMINI_BASE_URL="..."
    ```
  </Step>
  <Step title="Reload Shell Configuration">
    ```bash
    source ~/.bashrc  # or ~/.zshrc or ~/.config/fish/config.fish
    ```
  </Step>
</Steps>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Monitor Usage & Savings"
    href="https://www.llmadaptive.uk/dashboard"
    icon="chart-line"
  >
    Track your cost savings and usage analytics in real-time
  </Card>
  <Card
    title="API Documentation"
    href="/api-reference/chat-completions"
    icon="book"
  >
    Learn about Adaptive's API capabilities and advanced features
  </Card>
  <Card
    title="More CLI Tools"
    href="/developer-tools/grok-cli"
    icon="terminal"
  >
    Explore other CLI tools with Adaptive integration
  </Card>
  <Card
    title="Advanced Routing"
    href="/features/intelligent-routing"
    icon="route"
  >
    Learn about intelligent model routing and load balancing
  </Card>
</CardGroup>

---

<Note>
**Was this page helpful?** Contact us at [info@llmadaptive.uk](mailto:info@llmadaptive.uk) for feedback or assistance with your Gemini CLI integration.
</Note>
