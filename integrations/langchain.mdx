---
title: "LangChain"
description: "Connect LangChain with Adaptive for intelligent routing"
icon: "link"
---

## Quick Setup

1. **Install LangChain with OpenAI**:

<CodeGroup>
```bash Python
pip install langchain langchain-openai
```

```bash JavaScript/Node.js  
npm install langchain @langchain/openai
```
</CodeGroup>

2. **Use Adaptive as your base URL**:

<CodeGroup>
```python Python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    api_key="your-adaptive-api-key",
    base_url="https://www.llmadaptive.uk/api/v1",
    model="" # Empty string enables intelligent routing
)

response = llm.invoke("Explain machine learning simply")
print(response.content)
```

```javascript JavaScript/Node.js
import { ChatOpenAI } from "@langchain/openai";

const llm = new ChatOpenAI({
  apiKey: "your-adaptive-api-key",
  baseURL: "https://www.llmadaptive.uk/api/v1", 
  model: "" // Empty string enables intelligent routing
});

const response = await llm.invoke("Explain quantum computing");
console.log(response.content);
```
</CodeGroup>

That's it! Your LangChain code now uses intelligent routing.

## Common Patterns

### Streaming Responses

<CodeGroup>
```python Python
for chunk in llm.stream("Tell me a story about AI"):
    print(chunk.content, end="", flush=True)
```

```javascript JavaScript
const stream = await llm.stream("Tell me a story about AI");
for await (const chunk of stream) {
  process.stdout.write(chunk.content);
}
```
</CodeGroup>

### Chains and Memory

<CodeGroup>
```python Python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["topic"],
    template="Write a brief summary about {topic}"
)

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(topic="artificial intelligence")
print(result)
```

```javascript JavaScript
import { LLMChain } from "langchain/chains";
import { PromptTemplate } from "@langchain/core/prompts";

const prompt = PromptTemplate.fromTemplate(
  "Write a brief summary about {topic}"
);

const chain = new LLMChain({ llm, prompt });
const result = await chain.call({ topic: "artificial intelligence" });
console.log(result.text);
```
</CodeGroup>

### Function/Tool Calling

<CodeGroup>
```python Python
from langchain.tools import tool

@tool
def get_weather(location: str) -> str:
    """Get the current weather for a location."""
    return f"Weather in {location}: Sunny, 72°F"

# Use with agents or tool-calling chains
tools = [get_weather]
# Your agent setup here...
```

```javascript JavaScript
import { DynamicTool } from "@langchain/core/tools";

const weatherTool = new DynamicTool({
  name: "get_weather",
  description: "Get the current weather for a location",
  func: async (location) => {
    return `Weather in ${location}: Sunny, 72°F`;
  },
});

// Use with agents or tool-calling chains
const tools = [weatherTool];
```
</CodeGroup>

## What You Get

<CardGroup cols={2}>
  <Card title="Same LangChain API" icon="check">
    All LangChain features work without any changes
  </Card>
  <Card title="Intelligent Routing" icon="brain">
    Automatic model selection for each request
  </Card>
  <Card title="Cost Optimization" icon="dollar-sign">
    Significant savings through smart provider selection
  </Card>
  <Card title="Provider Transparency" icon="eye">
    See which AI provider was used in response metadata
  </Card>
</CardGroup>

## Environment Variables

<CodeGroup>
```bash .env
ADAPTIVE_API_KEY=your-adaptive-api-key
```

```python Python usage
import os
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    api_key=os.getenv("ADAPTIVE_API_KEY"),
    base_url="https://www.llmadaptive.uk/api/v1",
    model=""
)
```

```javascript JavaScript usage
import { ChatOpenAI } from "@langchain/openai";

const llm = new ChatOpenAI({
  apiKey: process.env.ADAPTIVE_API_KEY,
  baseURL: "https://www.llmadaptive.uk/api/v1",
  model: ""
});
```
</CodeGroup>

## Migration from OpenAI

Simply change your base URL - everything else stays the same:

<CodeGroup>
```python Before/After (Python)
# Before
llm = ChatOpenAI(
    api_key="sk-openai-key",
    # base_url defaults to OpenAI
    model="gpt-4"
)

# After  
llm = ChatOpenAI(
    api_key="your-adaptive-api-key",     # ← New API key
    base_url="https://www.llmadaptive.uk/api/v1", # ← Add this line
    model=""  # ← Empty for intelligent routing
)
```

```javascript Before/After (JavaScript)
// Before
const llm = new ChatOpenAI({
  apiKey: "sk-openai-key",
  // baseURL defaults to OpenAI
  model: "gpt-4"
});

// After
const llm = new ChatOpenAI({
  apiKey: "your-adaptive-api-key",        // ← New API key
  baseURL: "https://www.llmadaptive.uk/api/v1", // ← Add this line  
  model: ""  // ← Empty for intelligent routing
});
```
</CodeGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="More Examples" href="/examples/basic-chat" icon="code">
    See complete working examples with LangChain
  </Card>
  <Card title="API Reference" href="/api-reference/chat-completions" icon="book">
    Explore all available options and parameters
  </Card>
</CardGroup>