---
title: "Basic Chat Implementation"
description: "Simple chat implementation using Adaptive's OpenAI-compatible API"
icon: "message-circle"
---

# Basic Chat Implementation

This example shows how to implement a basic chat application using Adaptive's API as a drop-in replacement for OpenAI.

## Quick Setup

Replace your OpenAI base URL with Adaptive's endpoint:

```python
import openai

client = openai.OpenAI(
    base_url="https://api.llmadaptive.uk/v1",
    api_key="your-adaptive-api-key"
)

# Basic chat completion
response = client.chat.completions.create(
    model="gpt-3.5-turbo",  # Adaptive will optimize routing
    messages=[
        {"role": "user", "content": "Hello! How can you help me today?"}
    ]
)

print(response.choices[0].message.content)
```

## JavaScript/Node.js Example

```javascript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'https://api.llmadaptive.uk/v1',
  apiKey: 'your-adaptive-api-key',
});

async function basicChat() {
  const completion = await client.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [
      { role: 'user', content: 'What are the benefits of using Adaptive?' }
    ],
  });

  console.log(completion.choices[0].message.content);
}

basicChat();
```

## cURL Example

```bash
curl https://api.llmadaptive.uk/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-adaptive-api-key" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "user", "content": "Tell me about cost optimization"}
    ]
  }'
```

## Cost Comparison

**Traditional OpenAI Direct:**
- GPT-3.5-turbo: $3.00 per 1M input tokens
- Total cost for 10K messages: ~$30

**With Adaptive Smart Routing:**
- Optimized routing to cheaper models (e.g., Gemini Flash: $0.075/1M)
- Adaptive overhead: $0.10/1M input + $0.20/1M output
- Total cost for 10K messages: ~$1
- **Savings: 97%**

## Key Features

- **Drop-in Replacement**: Use your existing OpenAI SDK
- **Automatic Optimization**: Adaptive selects the best model for each request
- **Cost Savings**: Typically 60-97% cost reduction
- **Same Quality**: Intelligent routing maintains response quality
- **No Code Changes**: Just update the base URL and API key

## Error Handling

```python
try:
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "Hello"}]
    )
    print(response.choices[0].message.content)
except openai.APIError as e:
    print(f"API error occurred: {e}")
except openai.RateLimitError as e:
    print(f"Rate limit exceeded: {e}")
```

## Next Steps

- Try the [Streaming Chat Example](/examples/streaming-chat)
- Learn about [Intelligent Routing](/features/intelligent-routing)
- Explore [Integration Guides](/integrations/openai-sdk)